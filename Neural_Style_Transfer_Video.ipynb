{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wlX0M9XY5YEi"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "IS1OGWMJ9d7t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3IxaixmK32zv"
      },
      "outputs": [],
      "source": [
        "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q4UEFM4936mt"
      },
      "outputs": [],
      "source": [
        "#read image, convert to tensor, normalize and resize\n",
        "def image_read(image):\n",
        "  max_dim=512\n",
        "  image= tf.convert_to_tensor(image, dtype = tf.float32)\n",
        "  image= image/255.0\n",
        "  shape = tf.cast(tf.shape(image)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim/long_dim\n",
        "  new_shape = tf.cast(shape*scale, tf.int32)\n",
        "  new_image = tf.image.resize(image, new_shape)\n",
        "  new_image = new_image[tf.newaxis, :]\n",
        "\n",
        "  return new_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nANxEouh3_sj"
      },
      "outputs": [],
      "source": [
        "\n",
        "#convert tensor to numpy array\n",
        "def tensor_toimage(tensor):\n",
        "  tensor =tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0]==1\n",
        "    tensor=tensor[0]\n",
        "\n",
        "  return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0E4gBxxH4FdE"
      },
      "outputs": [],
      "source": [
        "style_im = cv2.imread(\"/content/style.jpg\")\n",
        "style_im = cv2.cvtColor(style_im, cv2.COLOR_BGR2RGB)\n",
        "style_im = image_read(style_im)\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1YmrD7b4Nkz"
      },
      "outputs": [],
      "source": [
        "\n",
        "#in order to get the size of width and shape of video, we used first frame of video\n",
        "ret, frame = cap.read()\n",
        "frame_width = image_read(frame)[0].shape[1]\n",
        "frame_height= image_read(frame)[0].shape[0]\n",
        "\n",
        "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'XVID'), 10,\n",
        "                      (frame_width,frame_height))\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = image_read(frame)\n",
        "    stylized_frame = hub_model(tf.constant(frame), tf.constant(style_im))[0]\n",
        "    image = tensor_toimage(stylized_frame)\n",
        "    out.write(image)\n",
        "  else:\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPOPZ3am4Xgd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}